{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "###читаем даатасет c фичами фильмов\n",
    "df_f = pd.read_csv('./movie_titles.csv', names=['MovieID', 'Year', 'Title'])\n",
    "df_f = df_f.set_index('MovieID')\n",
    "\n",
    "###читаем даатасет с инфой о пользователях\n",
    "f = open('./combined_data_1.txt')\n",
    "file = f.read()\n",
    "\n",
    "movieID_u = list(map(lambda x: int(x[:-1]), re.findall(r'\\d+\\:', file)))\n",
    "df_u = re.split(r'\\d+\\:', file)\n",
    "df_u = df_u[1:]    \n",
    "\n",
    "df = []\n",
    "for df_i, movieID_i in zip(df_u, movieID_u):\n",
    "    sub_df = pd.read_csv(StringIO(df_i), names=['UserID', 'Score', 'Date'])\n",
    "    sub_df['MovieID'] = movieID_i\n",
    "    df.append(sub_df)\n",
    "\n",
    "\n",
    "df = pd.concat(df)\n",
    "df_f = df_f.drop(df_f[df_f.index>df.MovieID.unique().shape[0]].index)\n",
    "#print(df_f)\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_size = df.UserID.unique().shape[0]\n",
    "m_size = df.MovieID.unique().shape[0]\n",
    "#y_size = df_f.Year.unique().shape[0]\n",
    "#s_size = df.Date.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['UserID', 'MovieID'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_targ = df.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### разреженная матрица\n",
    "sm = lil_matrix((df.shape[0], u_size + m_size))\n",
    "#print(sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-116-e9e3657227f4>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-116-e9e3657227f4>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    #print(sm[0,0])\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "temp = df.UserID.iat[0]\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    \n",
    "    if(temp<df.UserID.iat[i]):\n",
    "        j+=1\n",
    "        temp = df.UserID.iat[i]\n",
    "        \n",
    "    sm[i, j] = 1\n",
    "    sm[i, u_size + df.MovieID.iat[i]-1] = 1\n",
    "    \n",
    "    if i % 50000 == 0:\n",
    "        #print(\"\\r Progress: {}/{} ({}%)\".format(i, df.shape[0], int(((i+1) / df.shape[0]) * 100)), end=\"\")\n",
    "    #print(i, j, sm[i,j])\n",
    "    #print(i, j1, sm[i,j1])\n",
    "print(sm[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sparse_df_1.bin']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = csr_matrix(sm)\n",
    "joblib.dump(sm, 'sparse_df_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = joblib.load('sparse_df_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24053764, 475257)\n",
      "(24053764,)\n"
     ]
    }
   ],
   "source": [
    "print(sm.shape)\n",
    "print(df_targ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По лемме 1 нелинейную часть можно представить в виде: $\\sum_{i=1}^n \\sum_{j=i+1}^n \\langle {v}_i, {v}_f\\rangle x_ix_j = \\frac{1}{2}\\sum_{f=1}^k \\left( \\left(\\sum_{i=1}^n v_{i,f}x_i \\right)^2 - \\sum_{i=1}^n v^2_{i,f}x^2_i \\right)$\n",
    "<br>\n",
    "Производная $\\frac{dy}{dv}$ нелинейной части бдует следующей:\n",
    "<br>\n",
    "(1) = $\\left( \\left( \\sum_{i=1}^n v_{i,f}x_i \\right)^2 \\right)' _{v_if} = 2\\sum_{i=1}^n \\left(v_{i,f}x_i \\sum_{k=1}^n x_k\\right)$ или в матричном виде $\\sum_{f=1}^k2 (X\\mathbb{1})^TXV_f$\n",
    "<br>\n",
    "(2) = $ \\left( \\sum_{i=1}^n v_{i,f}^2x_i^2 \\right)' _{v_if} = 2\\sum_{i=1}^n v_{i,f}x_i^2 $ или в матричном виде $\\sum_{f=1}^k2 X^TXV_f$\n",
    "<br>\n",
    "<br>\n",
    "Тогда\n",
    "<br>\n",
    "$\\frac{dy}{dv_f} = \\frac{1}{2}\\sum_{f=1}^k \\left( (1) - (2) \\right)$ или в матричном виде $\\sum_{f=1}^k(X\\mathbb{1}-X)^TXV_f$\n",
    "<br>\n",
    "<br>\n",
    "И тогда $\\frac{dy}{dv}$ в матричном виде $(X\\mathbb{1}-X)^TXV\\mathbb{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(x, y):\n",
    "    return np.sqrt(np.sum(np.power(y - x, 2)) / y.shape[0])\n",
    "\n",
    "\n",
    "def narrTheta(lr, iter_num):\n",
    "    return lr / np.sqrt(iter_num)\n",
    "\n",
    "\n",
    "def sgdFFM(X, y, max_iter=1e3, step=1e-3, epsilon=1e-6, batch_size=256, k=9):\n",
    "    w0 = 0\n",
    "    iter_num = 1\n",
    "    N = X.shape[0]\n",
    "    np.random.seed(42)\n",
    "    w1 = np.random.normal(size=X.shape[1])\n",
    "    V = np.random.normal(size=(X.shape[1], k))\n",
    "    #V = np.zeros((X.shape[1], k))\n",
    "\n",
    "    while iter_num <= max_iter:\n",
    "        random_batch = np.random.choice(N, batch_size)\n",
    "        new_y = predict(X[random_batch, :], V, w0, w1)\n",
    "        # print(X[random_batch].shape)\n",
    "\n",
    "        dy = 2 * (new_y - y[random_batch])\n",
    "        # print(iter_num, dy)\n",
    "        w0 -= dy.mean() * step\n",
    "        w1 -= X[random_batch, :].T @ dy * step / batch_size#narrTheta(step, iter_num)\n",
    "        for f in range(k):    \n",
    "            # (256*8 . 256*1) = 256*8\n",
    "            dA = X[random_batch, :]*(X[random_batch, :]@V[:,f]).reshape(-1, 1)\n",
    "            #print(dA.shape)            \n",
    "            #256*8x8*1 = 256*8\n",
    "            dB = (X[random_batch, :]**2)*V[:,f]\n",
    "            #print(dB.shape)\n",
    "            #print(dy.shape)\n",
    "            V[:,f] -= step*(dy.reshape(-1, 1)*(dA-dB)).mean(axis=0)\n",
    "        \n",
    "        iter_num += 1\n",
    "        if (np.linalg.norm(y[random_batch] - new_y) < epsilon): \n",
    "            print(np.linalg.norm(y[random_batch] - new_y))\n",
    "            return w0, w1, V\n",
    "        \n",
    "        if (iter_num%100==0):\n",
    "            print(np.linalg.norm(y[random_batch] - new_y))\n",
    "        \n",
    "    return w0, w1, V\n",
    "\n",
    "def nonLin(X, V):\n",
    "    A = (X@V)**2\n",
    "    B = (X**2)@(V**2)\n",
    "    return 1/2*((A-B)@np.ones(V.shape[1]))\n",
    "\n",
    "def predict(X, V, w0, w1):\n",
    "    return w0 + X @ w1 + nonLin(X, V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Проверим на генерации</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977.2733061612314\n",
      "1710.4185793622946\n",
      "1288.3873723470788\n",
      "1099.1480132801491\n",
      "903.6936800562227\n",
      "741.4538711350989\n",
      "605.001122659824\n",
      "528.9393984546095\n",
      "395.1072109291937\n",
      "345.77646120090435\n",
      "271.4200441533309\n",
      "216.11524887500923\n",
      "201.24945151300895\n",
      "150.7270130620796\n",
      "121.4364666279503\n",
      "107.42766557811362\n",
      "87.65956852146452\n",
      "69.9404092961646\n",
      "53.51635485562993\n",
      "43.148232573779545\n",
      "36.01983100153369\n",
      "28.901169495232978\n",
      "24.65701114454576\n",
      "20.679405860195534\n",
      "16.936169098090634\n",
      "13.66466581950324\n",
      "11.27120010322844\n",
      "9.262971317090653\n",
      "7.438121429334432\n",
      "6.3082289055910215\n",
      "4.841573737697555\n",
      "4.397997551778146\n",
      "3.4295085917323047\n",
      "3.1326874859099103\n",
      "2.4261300380602724\n",
      "1.770960085570563\n",
      "1.6055020961967106\n",
      "1.355123967167543\n",
      "0.9840130111573284\n",
      "0.886940057827982\n",
      "0.691355419113849\n",
      "0.6120882682780324\n",
      "0.47394482256921355\n",
      "0.40351908194109476\n",
      "0.32835436342518826\n",
      "0.29606317769677365\n",
      "0.22890237894792187\n",
      "0.19004186786675753\n",
      "0.17048014113485804\n",
      "0.1311799750556162\n",
      "0.12835403427069106\n",
      "0.10806101062948913\n",
      "0.08446707260101619\n",
      "0.06834581194721709\n",
      "0.062236898795606385\n",
      "0.05423401652573282\n",
      "0.04948557009368508\n",
      "0.04405430172137095\n",
      "0.034636146520714214\n",
      "0.033649460091417845\n",
      "0.033777159509665124\n",
      "0.024607513235051243\n",
      "0.02304511831820187\n",
      "0.022408717453774443\n",
      "0.022812608183160155\n",
      "0.02046663723669862\n",
      "0.01671924507292272\n",
      "0.015420487610782171\n",
      "0.015202402050389254\n",
      "0.015312070198932796\n",
      "0.013513147248900282\n",
      "0.012404394316250416\n",
      "0.009444085817850417\n",
      "0.010498490559425646\n",
      "0.010628379180143975\n",
      "0.008943591402898961\n",
      "0.009378018130149322\n",
      "0.00799282639667988\n",
      "0.006637358526061926\n",
      "0.00701073442528894\n",
      "0.0061719412511469255\n",
      "0.006639333927496017\n",
      "0.00653047180642383\n",
      "0.006635341418008305\n",
      "0.005008555402411928\n",
      "0.005134519881739504\n",
      "0.004732786581889891\n",
      "0.0049296496318009435\n",
      "0.0036992683378218602\n",
      "0.0039884477823121465\n",
      "0.0034946124479988076\n",
      "0.003469482387975485\n",
      "0.0029502124259017455\n",
      "0.002497975534872383\n",
      "0.0029740507432581987\n",
      "0.002446624433187346\n",
      "0.002179852641102141\n",
      "0.002214106577107079\n",
      "0.002103825343655207\n",
      "0.0017228746360389827\n",
      "1919.263171467864\n",
      "1708.847707634593\n",
      "1324.7825892841483\n",
      "1114.4710235231657\n",
      "927.2100897870212\n",
      "759.6169280351361\n",
      "641.5920055045575\n",
      "534.2404981870171\n",
      "402.51841951710895\n",
      "350.0177833019802\n",
      "267.23612483576005\n",
      "214.25375524687146\n",
      "194.64853410200686\n",
      "143.23808644011868\n",
      "119.55671952460342\n",
      "102.97489115922208\n",
      "91.37019258205332\n",
      "69.18919751785519\n",
      "53.88166026487174\n",
      "44.86289934149849\n",
      "35.25902972313197\n",
      "29.423007316596784\n",
      "25.755190482891027\n",
      "21.489797677039636\n",
      "17.733134277205803\n",
      "13.887184778277797\n",
      "11.083652649606911\n",
      "9.735267354345318\n",
      "7.591412995738328\n",
      "6.401112492083831\n",
      "5.025074610014789\n",
      "4.239951396648331\n",
      "3.3437979363423294\n",
      "3.1496395030719087\n",
      "2.3860233816399123\n",
      "1.8527008419117934\n",
      "1.6633242017925447\n",
      "1.3133501751441592\n",
      "1.014927105740054\n",
      "0.9601610471620148\n",
      "0.7583843994244871\n",
      "0.6430359993287015\n",
      "0.47333608482143985\n",
      "0.39853432679995643\n",
      "0.36679080729159935\n",
      "0.3081322563692934\n",
      "0.24708778082155974\n",
      "0.20544579572354155\n",
      "0.18035364337889978\n",
      "0.14097608531766695\n",
      "0.1289157817821403\n",
      "0.1015775902648515\n",
      "0.09083379300580491\n",
      "0.06947367030061966\n",
      "0.0654319385141798\n",
      "0.05348337018253196\n",
      "0.04693982873977114\n",
      "0.04069972890199512\n",
      "0.03544447593251991\n",
      "0.02598809606131253\n",
      "0.025003457739603448\n",
      "0.0262860955984462\n",
      "0.021222880591456668\n",
      "0.01804300715450592\n",
      "0.015478251860571697\n",
      "0.015911853001176098\n",
      "0.011829756437868549\n",
      "0.010921666517442469\n",
      "0.01014029499661548\n",
      "0.008505372293328614\n",
      "0.007159739474880945\n",
      "0.007196989833183279\n",
      "0.007419573345727842\n",
      "0.005810236573780139\n",
      "0.00511364894594168\n",
      "0.004091754144522811\n",
      "0.004004129098851949\n",
      "0.0032666309208384614\n",
      "0.0026663675578510273\n",
      "0.0034699413498578175\n",
      "0.0028925985770333856\n",
      "0.002168043462722358\n",
      "0.0021427087929686496\n",
      "0.001982259040595247\n",
      "0.0016624483518668447\n",
      "0.0014266288251387111\n",
      "0.0013159026478037287\n",
      "0.0011630032338384735\n",
      "0.0010355264810118505\n",
      "0.001045068437587365\n",
      "0.0008824666308528383\n",
      "0.0007268097298811249\n",
      "0.0006749259999227315\n",
      "0.0005363204082698657\n",
      "0.0005461667946620364\n",
      "0.0005215762053277663\n",
      "0.0004263395108937104\n",
      "0.00039509450089433097\n",
      "0.0003450142293593104\n",
      "0.00026814905807925546\n",
      "2111.9689525380463\n",
      "1716.6850301333466\n",
      "1387.797051953045\n",
      "1096.3670499760785\n",
      "950.2959585158208\n",
      "757.9193328901406\n",
      "626.9336358931828\n",
      "526.1794343209468\n",
      "408.05480274955204\n",
      "342.4681493538054\n",
      "250.6455898563795\n",
      "221.76386882771894\n",
      "185.22163487797795\n",
      "138.73798766453066\n",
      "116.77293280308562\n",
      "93.30652977824936\n",
      "85.98231293801291\n",
      "65.82316127415869\n",
      "53.74378926088163\n",
      "43.17972514067229\n",
      "33.317489672194924\n",
      "27.67029983242646\n",
      "24.73119455765923\n",
      "20.324879955177728\n",
      "17.384788742996076\n",
      "13.076324091993987\n",
      "11.285309352964617\n",
      "9.680967062035883\n",
      "6.999008721750763\n",
      "6.274692244339262\n",
      "4.728477572970413\n",
      "4.158797000979749\n",
      "3.3867472692351694\n",
      "3.0927331789408274\n",
      "2.3095272955579325\n",
      "1.7845756576725347\n",
      "1.5303743268850498\n",
      "1.1684936043504832\n",
      "1.0293799710484763\n",
      "0.9620165721385648\n",
      "0.7746291092209977\n",
      "0.6461044682032827\n",
      "0.5131729288538474\n",
      "0.4619236846289937\n",
      "0.367696448772061\n",
      "0.33164764698796134\n",
      "0.2771098153469754\n",
      "0.22985662653650324\n",
      "0.18201183245928157\n",
      "0.18908980480833776\n",
      "0.1582425410273397\n",
      "0.1457531796406189\n",
      "0.12468290252320194\n",
      "0.1059600685613549\n",
      "0.11201374307694974\n",
      "0.09048505057689987\n",
      "0.07575465265703388\n",
      "0.07495244461937785\n",
      "0.06310362424308094\n",
      "0.057772859899612214\n",
      "0.0560190662428788\n",
      "0.04332291609379119\n",
      "0.04299699333602801\n",
      "0.03370623216223447\n",
      "0.03466139210011843\n",
      "0.0348090492483401\n",
      "0.0257896541745638\n",
      "0.02958213550631692\n",
      "0.026674531791952255\n",
      "0.023566037375278043\n",
      "0.020321007615083417\n",
      "0.01709315852209995\n",
      "0.015479427645340936\n",
      "0.015527362311547045\n",
      "0.014370072898674187\n",
      "0.01290531719763241\n",
      "0.012400780711650301\n",
      "0.010741150492343584\n",
      "0.009868178029790134\n",
      "0.008989926019644812\n",
      "0.007253564700345297\n",
      "0.008102004014843903\n",
      "0.0064587911945361235\n",
      "0.0064837085078112405\n",
      "0.005509653799964938\n",
      "0.004509696332029732\n",
      "0.0043017143795161744\n",
      "0.004302505934838676\n",
      "0.003875903921882819\n",
      "0.00315200969094514\n",
      "0.003473714856416135\n",
      "0.0027308549200509248\n",
      "0.0028007278307610843\n",
      "0.002446534593761091\n",
      "0.0020425502884723564\n",
      "0.001996838432989102\n",
      "0.0018590400147165407\n",
      "0.0014387755298312303\n",
      "0.001543068493733089\n",
      "0.00140893944531577\n",
      "2195.6893014633697\n",
      "1711.0569908612922\n",
      "1443.3664468023449\n",
      "1139.843029021285\n",
      "955.2522648561245\n",
      "744.6861081727742\n",
      "603.4628423817386\n",
      "513.2410906637268\n",
      "402.7603250270826\n",
      "355.7783460369605\n",
      "241.07744195338577\n",
      "225.71512831347474\n",
      "188.8749226070083\n",
      "132.74831607436502\n",
      "116.23115919636801\n",
      "91.64594199790781\n",
      "88.17878760426072\n",
      "63.811190335266836\n",
      "55.22354059254848\n",
      "44.78600464036651\n",
      "35.25330012117475\n",
      "26.969948958043073\n",
      "24.928329899412812\n",
      "21.40323291361602\n",
      "17.665388075015855\n",
      "12.838885114228779\n",
      "11.62734740188303\n",
      "9.902940902426046\n",
      "7.171968091894681\n",
      "6.45994513496051\n",
      "5.031928273892799\n",
      "4.2605047550429065\n",
      "3.332456278513991\n",
      "2.9569838951653367\n",
      "2.1991553265013177\n",
      "1.7797933754538788\n",
      "1.471663811472754\n",
      "1.1938899689737668\n",
      "1.0639958371885436\n",
      "0.8997836136026631\n",
      "0.7442317949925142\n",
      "0.5503312129192046\n",
      "0.4726570537004474\n",
      "0.38471760419595846\n",
      "0.33732617284006533\n",
      "0.2750619179225215\n",
      "0.2258650774050936\n",
      "0.19490695794416452\n",
      "0.16498029440644754\n",
      "0.1429149700447761\n",
      "0.12449260268923315\n",
      "0.10036867331746877\n",
      "0.08101196043052074\n",
      "0.06532788474101131\n",
      "0.06071676920781423\n",
      "0.059598947635945254\n",
      "0.04893350062310065\n",
      "0.0439001086423122\n",
      "0.03620390735838217\n",
      "0.034121308816517405\n",
      "0.030317842341256198\n",
      "0.024542872468252888\n",
      "0.0253619214542716\n",
      "0.022131865119892496\n",
      "0.019160576847613908\n",
      "0.01860437020736943\n",
      "0.0148234732261141\n",
      "0.016171356004891134\n",
      "0.013047080097671597\n",
      "0.012043125694410404\n",
      "0.010797527792011308\n",
      "0.0092547384921617\n",
      "0.009803670449086428\n",
      "0.008028040628077866\n",
      "0.00682424120679651\n",
      "0.006388643168160031\n",
      "0.006604485622328951\n",
      "0.005705256058830686\n",
      "0.005647682756566456\n",
      "0.004685611379646843\n",
      "0.004497880620042557\n",
      "0.004872660702760633\n",
      "0.004687395034545378\n",
      "0.0038803193605554537\n",
      "0.0038342460803236773\n",
      "0.0030612320087650526\n",
      "0.0026032580048632945\n",
      "0.0028602886397302535\n",
      "0.002256244813292096\n",
      "0.002346900018003289\n",
      "0.0022689187609325895\n",
      "0.002029492003728679\n",
      "0.0016098087551414066\n",
      "0.0015062439706631505\n",
      "0.001310971729891385\n",
      "0.001204933363616166\n",
      "0.0010241323420220637\n",
      "0.001289964098716169\n",
      "0.0009869358128698148\n",
      "0.0008425399949274437\n",
      "2211.515343354897\n",
      "1704.3054358100037\n",
      "1464.4591964427514\n",
      "1169.9505349289393\n",
      "953.8248551388828\n",
      "739.5693076658782\n",
      "640.6352855564061\n",
      "511.81569151217775\n",
      "414.42341834187687\n",
      "355.81636334115007\n",
      "257.0136600698011\n",
      "239.08378197914533\n",
      "180.78098866229166\n",
      "144.1967563775285\n",
      "125.8154312977238\n",
      "96.43855434059662\n",
      "89.4896411463367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.68483772760368\n",
      "60.2503755668228\n",
      "48.91786983332927\n",
      "38.725075916408\n",
      "28.738853581498564\n",
      "27.340622946384165\n",
      "21.656662394905165\n",
      "19.11900415819291\n",
      "14.807504840968127\n",
      "13.00533496464939\n",
      "10.832926575781846\n",
      "7.598867550966291\n",
      "6.877325024256105\n",
      "5.9342683148343465\n",
      "4.4922364748519\n",
      "3.8289490064215403\n",
      "3.283374717902527\n",
      "2.5973221275229124\n",
      "2.1762071632033044\n",
      "1.6811770333410492\n",
      "1.470682883512652\n",
      "1.2976182222228752\n",
      "1.0858892539492069\n",
      "0.8999976237363952\n",
      "0.7581258065827252\n",
      "0.6156406623972895\n",
      "0.5457954655170122\n",
      "0.4450694692798333\n",
      "0.36604965976018805\n",
      "0.2909847561980066\n",
      "0.2838451595663845\n",
      "0.2595776833711953\n",
      "0.24422506974167546\n",
      "0.19641125071956803\n",
      "0.1848889865012057\n",
      "0.1580500254501883\n",
      "0.15695159539799228\n",
      "0.13051222975238613\n",
      "0.11084401975430809\n",
      "0.10430126975905667\n",
      "0.0863963936220372\n",
      "0.07234798428166533\n",
      "0.06811975557570499\n",
      "0.05898679209224424\n",
      "0.06456721824624058\n",
      "0.055270877359147014\n",
      "0.05235321727809212\n",
      "0.04469718569274937\n",
      "0.04122862176048151\n",
      "0.030777925292432697\n",
      "0.031071988948692265\n",
      "0.03505506238887335\n",
      "0.02931933121038292\n",
      "0.025490882655503998\n",
      "0.02406617221121093\n",
      "0.02400195214741328\n",
      "0.021704925566159747\n",
      "0.020196070478575797\n",
      "0.01610042273283922\n",
      "0.014104510852745337\n",
      "0.0165660097125699\n",
      "0.013786932423266162\n",
      "0.011893481232074274\n",
      "0.011090429078591228\n",
      "0.010218920123500235\n",
      "0.009964000540038643\n",
      "0.008723260098201572\n",
      "0.007538990162620123\n",
      "0.007472788283118071\n",
      "0.006211568064851206\n",
      "0.005589001074485332\n",
      "0.0055964289583430825\n",
      "0.004988009231480069\n",
      "0.004677689575193563\n",
      "0.0036981702378384353\n",
      "0.0036644870985971614\n",
      "0.003732620328250729\n",
      "0.0034201192260507212\n",
      "0.0033365174553434893\n",
      "0.002476476520997123\n",
      "0.0023418970817011137\n",
      "0.00175892206212982\n",
      "0.0022089495200071224\n",
      "Fold 5 \n",
      "Обучающая: \n",
      " [-7.40070399e-06  1.27949681e-05  1.14960343e-06 ...  1.39590466e-05\n",
      "  5.55010804e-05  8.10801626e-06] \n",
      "Тестовая: \n",
      " [-4.24946428e-07  2.54122470e-05  2.46416634e-05 ...  2.70696263e-05\n",
      "  2.94143826e-05 -9.24693422e-05] \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y, coefs = make_regression(n_samples=10000, n_features=8, n_targets=1, n_informative=4, coef=True)\n",
    "\n",
    "folds_index = 5\n",
    "fold_size = round(X.shape[0] / folds_index)\n",
    "RMSE_test = []\n",
    "RMSE_train = []\n",
    "\n",
    "for i in range(folds_index):\n",
    "    test = X[i * fold_size:(i + 1) * fold_size]\n",
    "    testT = y[i * fold_size:(i + 1) * fold_size]\n",
    "    if i == 0:\n",
    "        train = X[(i + 1) * fold_size:, :]\n",
    "        trainT = y[(i + 1) * fold_size:]\n",
    "    else:\n",
    "        train = X[:i * fold_size, :]\n",
    "        trainT = y[:i * fold_size]\n",
    "        if i != 4:\n",
    "            train = np.concatenate((train, X[(i + 1) * fold_size:, :]))\n",
    "            trainT = np.concatenate([trainT, y[(i + 1) * fold_size:]])\n",
    "    \n",
    "    Target = trainT\n",
    "    Features = train\n",
    "    w0, w1, V = sgdFFM(Features, Target, 1e4, 1e-3)\n",
    "\n",
    "    train_pred = predict(Features, V, w0, w1)\n",
    "\n",
    "    RMSE_train.append(RMSE(train_pred, Target))\n",
    "    TargetT = testT\n",
    "    FeaturesT = test\n",
    "    test_pred = predict(FeaturesT, V, w0, w1)\n",
    "    RMSE_test.append(RMSE(test_pred, TargetT))\n",
    "\n",
    "print('Fold {}'.format(i + 1), '\\nОбучающая: \\n', train_pred - Target, '\\nТестовая: \\n', test_pred - TargetT, '\\n', '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test</th>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4      mean  \\\n",
       "rmse_train  0.000117  0.000019  0.000086  0.000059  0.000130  0.000082   \n",
       "rmse_test   0.000116  0.000019  0.000085  0.000062  0.000127  0.000082   \n",
       "\n",
       "                 std  \n",
       "rmse_train  0.000045  \n",
       "rmse_test   0.000044  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.vstack([RMSE_train, RMSE_test]), \n",
    "                  index=['rmse_train','rmse_test'])\n",
    "\n",
    "df = pd.concat([df, df.mean(axis=1).rename('mean'),\n",
    "                df.std(axis=1).rename('std')], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Фигачим на данных1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "matrix is not square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-4e55da8e8cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mTarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgdFFM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-80071123d118>\u001b[0m in \u001b[0;36msgdFFM\u001b[1;34m(X, y, max_iter, step, epsilon, batch_size, k)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0miter_num\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrandom_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mnew_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m# print(X[random_batch].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-80071123d118>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X, V, w0, w1)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mw0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mw1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnonLin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-120-80071123d118>\u001b[0m in \u001b[0;36mnonLin\u001b[1;34m(X, V)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnonLin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\programs\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__pow__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pow__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matrix is not square'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: matrix is not square"
     ]
    }
   ],
   "source": [
    "X = sm\n",
    "y = df_targ\n",
    "\n",
    "folds_index = 5\n",
    "fold_size = round(X.shape[0] / folds_index)\n",
    "RMSE_test = []\n",
    "RMSE_train = []\n",
    "\n",
    "for i in range(folds_index):\n",
    "    test = X[i * fold_size:(i + 1) * fold_size]\n",
    "    testT = y[i * fold_size:(i + 1) * fold_size]\n",
    "    if i == 0:\n",
    "        train = X[(i + 1) * fold_size:, :]\n",
    "        trainT = y[(i + 1) * fold_size:]\n",
    "    else:\n",
    "        train = X[:i * fold_size, :]\n",
    "        trainT = y[:i * fold_size]\n",
    "        if i != 4:\n",
    "            train = np.concatenate((train, X[(i + 1) * fold_size:, :]))\n",
    "            trainT = np.concatenate([trainT, y[(i + 1) * fold_size:]])\n",
    "    \n",
    "    Target = trainT\n",
    "    Features = train\n",
    "    w0, w1, V = sgdFFM(Features, Target, 1e4, 1e-3)\n",
    "\n",
    "    train_pred = predict(Features, V, w0, w1)\n",
    "\n",
    "    RMSE_train.append(RMSE(train_pred, Target))\n",
    "    TargetT = testT\n",
    "    FeaturesT = test\n",
    "    test_pred = predict(FeaturesT, V, w0, w1)\n",
    "    RMSE_test.append(RMSE(test_pred, TargetT))\n",
    "\n",
    "print('Fold {}'.format(i + 1), '\\nОбучающая: \\n', train_pred - Target, '\\nТестовая: \\n', test_pred - TargetT, '\\n', '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack([RMSE_train, RMSE_test]), \n",
    "                  index=['rmse_train','rmse_test'])\n",
    "\n",
    "df = pd.concat([df, df.mean(axis=1).rename('mean'),\n",
    "                df.std(axis=1).rename('std')], axis=1)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
